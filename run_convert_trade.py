import os
import glob
import subprocess
import json

from convert_cycle import process_top_pairs
from convert_logger import logger, safe_log
from quote_counter import can_request_quote

EXPLORE_MODE = int(os.getenv("EXPLORE_MODE", "0"))
EXPLORE_PAPER = int(os.getenv("EXPLORE_PAPER", "1"))
EXPLORE_MAX = int(os.getenv("EXPLORE_MAX", "2"))
EXPLORE_MIN_EDGE = float(os.getenv("EXPLORE_MIN_EDGE", "0.001"))
EXPLORE_MIN_LOT_FACTOR = float(os.getenv("EXPLORE_MIN_LOT_FACTOR", "0.5"))

logger.info(
    safe_log(
        f"[dev3] Explore: MODE={EXPLORE_MODE} PAPER={EXPLORE_PAPER} MAX={EXPLORE_MAX} "
        f"MIN_EDGE={EXPLORE_MIN_EDGE} MIN_LOT_FACTOR={EXPLORE_MIN_LOT_FACTOR}"
    )
)

if not can_request_quote():
    logger.warning(safe_log("[dev3] ‚õî –õ—ñ–º—ñ—Ç –∑–∞–ø–∏—Ç—ñ–≤ –¥–æ Convert API –¥–æ—Å—è–≥–Ω—É—Ç–æ. –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ —Ü–∏–∫–ª."))
    exit(0)

CACHE_FILES = [
    "signals.txt",
    "last_message.txt",
]


def cleanup() -> None:
    for path in CACHE_FILES:
        if os.path.exists(path):
            try:
                os.remove(path)
            except OSError:
                pass
    for temp in glob.glob(os.path.join("logs", "temp_*.json")):
        try:
            os.remove(temp)
        except OSError:
            pass
    # [dev3] –ù–µ –≤–∏–¥–∞–ª—è—î–º–æ top_tokens.json –Ω–∞ –ø–æ—á–∞—Ç–∫—É —Ç—Ä–µ–π–¥-—Ü–∏–∫–ª—É, –±–æ —Ñ–∞–π–ª
    # —Å—Ç–≤–æ—Ä—é—î—Ç—å—Å—è –≤ GPT-–µ—Ç–∞–ø—ñ –∑–∞ –≥–æ–¥–∏–Ω—É –¥–æ —Ç—Ä–µ–π–¥—É
    for qfile in glob.glob(os.path.join("logs", "quote_*.json")):
        try:
            os.remove(qfile)
        except OSError:
            pass
    for log_path in glob.glob(os.path.join("logs", "*.log")):
        try:
            if os.path.getsize(log_path) > 5 * 1024 * 1024:
                os.remove(log_path)
        except OSError:
            pass


def main() -> None:
    cleanup()
    logger.info(safe_log("[dev3] üîÑ –ó–∞–ø—É—Å–∫ convert —Ç—Ä–µ–π–¥–∏–Ω–≥—É"))
    try:
        logger.info(safe_log("[dev3] üìÑ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ —Ñ–∞–π–ª—É top_tokens.json..."))
        if not os.path.exists("top_tokens.json"):
            logger.warning(safe_log("[dev3] ‚õîÔ∏è –§–∞–π–ª top_tokens.json –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ó–∞–≤–µ—Ä—à—É—î–º–æ —Ü–∏–∫–ª."))
            return

        with open("top_tokens.json") as f:
            top_tokens = json.load(f)

        if not top_tokens:
            logger.warning(safe_log("[dev3] ‚õîÔ∏è –§–∞–π–ª top_tokens.json –ø–æ—Ä–æ–∂–Ω—ñ–π. –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ —Ç—Ä–µ–π–¥."))
            return

        logger.info(safe_log(f"[dev3] ‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(top_tokens)} –ø–∞—Ä –∑ top_tokens.json"))
        process_top_pairs(top_tokens)
    except Exception as e:
        logger.error(safe_log(f"[dev3] ‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ top_tokens.json: {e}"))
        return
    cleanup()
    logger.info(safe_log("[dev3] ‚úÖ –¶–∏–∫–ª –∑–∞–≤–µ—Ä—à–µ–Ω–æ"))

    # üß† –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
    logger.info(safe_log("[dev3] üìö –ü–æ—á–∏–Ω–∞—î–º–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ..."))
    try:
        subprocess.run(["python3", "train_convert_model.py", "--force-train"], check=True)
    except Exception as exc:
        logger.error(safe_log(f"[dev3] ‚ùå –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å –∑ –ø–æ–º–∏–ª–∫–æ—é: {exc}"))
        return
    logger.info(safe_log("[dev3] ‚úÖ –ù–∞–≤—á–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ"))

    predictions_path = os.path.join("logs", "predictions.json")
    if os.path.exists(predictions_path):
        try:
            os.remove(predictions_path)
        except OSError:
            pass


if __name__ == "__main__":
    main()
